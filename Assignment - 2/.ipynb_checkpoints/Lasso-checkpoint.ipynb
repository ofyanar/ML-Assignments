{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "69b5174d",
   "metadata": {},
   "source": [
    "# Answers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ea20248",
   "metadata": {},
   "source": [
    "# Questions 1 - 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "020a0691",
   "metadata": {},
   "source": [
    "## loading and splitting load_diabetes dataset from scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "59ed358a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_diabetes\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "diabetes = load_diabetes()\n",
    "X_train, X_test, y_train, y_test = train_test_split(diabetes.data, \n",
    "                                                   diabetes.target, random_state = 13)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8df4ce19",
   "metadata": {},
   "source": [
    "# Question 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "a97ce629",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.linear_model import Lasso\n",
    "\n",
    "lasso = Lasso().fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f87c1a5",
   "metadata": {},
   "source": [
    " ### The number of features used by lasso can be retreived using coef_, the size of which is the same as features used. This number is the same for both the training and the test sets. The names of features can be found using feature_names:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "1a5f6d93",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 3 features used by lasso for diabetes_load.\n",
      "And their names are: bmi, bp, s5\n"
     ]
    }
   ],
   "source": [
    "num_feats = np.sum(lasso.coef_ != 0)\n",
    "\n",
    "names = []\n",
    "for i in range(len(diabetes.feature_names)):\n",
    "    if lasso.coef_[i] != 0: \n",
    "        names.append(diabetes.feature_names[i])\n",
    "names = \", \".join(names)\n",
    "print(\"There are \" + str(num_feats) + \" features used by lasso for diabetes_load.\")\n",
    "print(\"And their names are: \" + names)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2afc5e64",
   "metadata": {},
   "source": [
    "### The coefficient of determination values for training and test sets are stored under appropriate variable names below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "cba57ceb",
   "metadata": {},
   "outputs": [],
   "source": [
    "cd_train = lasso.score(X_train, y_train)\n",
    "cd_test = lasso.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "66c4c837",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The training coefficient of determination for load_diabetes is: 0.3762122247795391\n",
      "The test coefficient of determination for load_diabetes is: 0.359767640353562\n"
     ]
    }
   ],
   "source": [
    "print(\"The training coefficient of determination for load_diabetes is: \" + str(cd_train))\n",
    "print(\"The test coefficient of determination for load_diabetes is: \" + str(cd_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c447d30",
   "metadata": {},
   "source": [
    "# Questions 4 - 6\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df1edeef",
   "metadata": {},
   "source": [
    "## Loading and splitting diabetes.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "84ed1472",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "new_diabetes_X = np.genfromtxt(\"diabetes.data\", delimiter = \"\", usecols = np.arange(10), skip_header = 1)\n",
    "new_diabetes_y = np.genfromtxt(\"diabetes.data\", delimiter = \"\", usecols = 10, skip_header = 1)\n",
    "\n",
    "new_X_train, new_X_test, new_y_train, new_y_test = train_test_split(new_diabetes_X, \n",
    "                                                   new_diabetes_y, random_state = 13)\n",
    "\n",
    "new_lasso = Lasso().fit(new_X_train, new_y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8680dbd4",
   "metadata": {},
   "source": [
    "### The features used by lasso for diabetes.data is identical to what it uses for load_diabetes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "34bb0e6b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 9 features used by lasso for diabetes.data\n",
      "And their names are: age, sex, bmi, bp, s1, s2, s3, s5, s6\n"
     ]
    }
   ],
   "source": [
    "num_feats = np.sum(new_lasso.coef_ != 0)\n",
    "names = []\n",
    "for i in range(len(diabetes.feature_names)):\n",
    "    if new_lasso.coef_[i] != 0: \n",
    "        names.append(diabetes.feature_names[i])\n",
    "names = \", \".join(names)\n",
    "print(\"There are \" + str(num_feats) + \" features used by lasso for diabetes.data\")\n",
    "print(\"And their names are: \" + names)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00241e8e",
   "metadata": {},
   "source": [
    "## The coefficient of determination (CD) values for training and test sets for diabetes.load:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c00d2cf2",
   "metadata": {},
   "source": [
    " ### The CD values for diabetes.data training and test sets are larger than their load_diabetes counterparts, values for the aforementioned dataset is closer to 1 therefore it's performance is better."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "41e56b47",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_cd_train = new_lasso.score(new_X_train, new_y_train)\n",
    "new_cd_test = new_lasso.score(new_X_test, new_y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "e66e8456",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The training coefficient of determination for diabetes.data is: 0.527799678598694\n",
      "The test coefficient of determination for diabetes.data is: 0.4206521413351825\n"
     ]
    }
   ],
   "source": [
    "print(\"The training coefficient of determination for diabetes.data is: \" + str(new_cd_train))\n",
    "print(\"The test coefficient of determination for diabetes.data is: \" + str(new_cd_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "081c111c",
   "metadata": {},
   "source": [
    "# Questions 7 - 8\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6cb1e69",
   "metadata": {},
   "source": [
    "## Preprocessing diabetes.data using StandardScaler "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "309436b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(new_X_train)\n",
    "\n",
    "X_train_scaled = scaler.transform(new_X_train)\n",
    "X_test_scaled = scaler.transform(new_X_test)\n",
    "\n",
    "scaled_lasso = Lasso().fit(X_train_scaled, new_y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "fa432c8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 7 features used by lasso for diabetes.data\n",
      "And their names are: sex, bmi, bp, s1, s3, s5, s6\n"
     ]
    }
   ],
   "source": [
    "num_feats = np.sum(scaled_lasso.coef_ != 0)\n",
    "names = []\n",
    "for i in range(len(diabetes.feature_names)):\n",
    "    if scaled_lasso.coef_[i] != 0: \n",
    "        names.append(diabetes.feature_names[i])\n",
    "names = \", \".join(names)\n",
    "print(\"There are \" + str(num_feats) + \" features used by lasso for diabetes.data\")\n",
    "print(\"And their names are: \" + names)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42a80c68",
   "metadata": {},
   "source": [
    "### CD for normalised data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "537c7213",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaled_cd_train = scaled_lasso.score(X_train_scaled, new_y_train)\n",
    "scaled_cd_test = scaled_lasso.score(X_test_scaled, new_y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68b1e3b4",
   "metadata": {},
   "source": [
    "### The expectation that the results below would be closer to (3) than (6) has been disproven. One reason for this may be that normalising data doesn't necessarily affect coefficient of determination as data is just rescaled at an even proportion accross test and training sets and the overall properties of lasso remain roughly unchanged. Additionally, the type of normalisation of data affects the final results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "e44dac9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The training coefficient of determination for diabetes.data is: 0.5325028908798705\n",
      "The test coefficient of determination for diabetes.data is: 0.44679521191597227\n"
     ]
    }
   ],
   "source": [
    "print(\"The training coefficient of determination for diabetes.data is: \" + str(scaled_cd_train))\n",
    "print(\"The test coefficient of determination for diabetes.data is: \" + str(scaled_cd_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81f3f90d",
   "metadata": {},
   "source": [
    "# Question 9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "fe374d50",
   "metadata": {},
   "outputs": [],
   "source": [
    "from random import randint as rand\n",
    "\n",
    "# First we find the indices where the coefficient is non-zero\n",
    "coef_indices = []\n",
    "\n",
    "for i in range(len(scaled_lasso.coef_)):\n",
    "    if scaled_lasso.coef_[i] != 0:\n",
    "        coef_indices.append(i)\n",
    "\n",
    "#list of number of features with non-zero coef\n",
    "num_features = [i for i in range(1, len(coef_indices) + 1)]\n",
    "\n",
    "# CD values stored in list below.\n",
    "CD_values = []\n",
    "\n",
    "# initial Regularization Parameter.\n",
    "C = 0.0001\n",
    "\n",
    "# the size of X_train_scaled used to slice X_train_scaled\n",
    "X_size = len(X_train_scaled) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "f8e42013",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The graph will contain len(non_zero_coef) plots with varying C's.\n",
    "# the C value is 2x, where x is the number of features used by lasso (max 7)\n",
    "for i in range (len(coef_indices)):\n",
    "    # least index of a non-zero feature\n",
    "    min_feat = coef_indices[i] + 1\n",
    "    # the X_train is sliced depending on how many features are used\n",
    "    X_train_sliced = X_train_scaled[:X_size, :min_feat]\n",
    "    X_test_sliced = X_test_scaled[:X_size, :min_feat]\n",
    "    CD = Lasso(alpha = C).fit(X_train_sliced, new_y_train).score(X_test_sliced, new_y_test)\n",
    "    CD_values.append(CD)  \n",
    "    C *= 10"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32e0a2e7",
   "metadata": {},
   "source": [
    "## The graph below shows a plot of R^2 against increasing number of features with non-zero coefficients. The regularization parameter varies, increasing +2 in each loop to give different R^2 values. \n",
    "\n",
    "### The curve shown has an slow peak at x = 6. My preference would be (6, 0.437) as it is the peak of the plot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "06ff0409",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x280d7f9d2b0>]"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# make CD_values into np array\n",
    "CD_values = np.array(CD_values)\n",
    "\n",
    "%matplotlib inline\n",
    "plt.scatter(num_features, CD_values)\n",
    "plt.plot(num_features, CD_values)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a20d6f1",
   "metadata": {},
   "source": [
    "# Question 10"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81ccb836",
   "metadata": {},
   "source": [
    "## Then we create the necessary variables, i.e. the list of C values in which our target regularisation parameter is, and best score and best_C variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "663c1874",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# create variables to store best_score and best regularisation parameter, C.\n",
    "best_score = 0\n",
    "best_C = 0\n",
    "\n",
    "# a grid for possible alpha values\n",
    "param_grid = {'alpha': [i*0.1 for i in range(1,100)]}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1b5c364",
   "metadata": {},
   "source": [
    "## We try all possible regularisation parameters in the list to find the best one against the validation set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "d35cbae2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# we will be using Lasso with GridSearchCV to find the optimal regularisation parameter.\n",
    "# using the scaled diabetes.data values with SVC cause an unidentified error which could not be resolved.\n",
    "grid_search = GridSearchCV(Lasso(), param_grid, cv = 5)\n",
    "\n",
    "grid_search.fit(X_train_scaled, new_y_train)\n",
    "\n",
    "best_score = grid_search.score(X_test_scaled, new_y_test)\n",
    "\n",
    "best_C = grid_search.best_params_['alpha']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "e9060515",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The best regularisation parameter:\n",
      "1.6\n"
     ]
    }
   ],
   "source": [
    "optimal_lasso = Lasso(alpha = best_C)\n",
    "optimal_lasso.fit(X_train_scaled, new_y_train)\n",
    "                  \n",
    "optimal_cd_train = optimal_lasso.score(X_train_scaled, new_y_train)\n",
    "optimal_cd_test = optimal_lasso.score(X_test_scaled, new_y_test)\n",
    "\n",
    "print(\"The best regularisation parameter:\")\n",
    "print(best_C)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "a42fd388",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 8 features used by optimal lasso for diabetes.data\n",
      "And their names are: sex, bmi, bp, s1, s2, s3, s5, s6\n"
     ]
    }
   ],
   "source": [
    "num_feats = np.sum(optimal_lasso.coef_ != 0)\n",
    "\n",
    "names = []\n",
    "for i in range(len(diabetes.feature_names)):\n",
    "    if optimal_lasso.coef_[i] != 0: \n",
    "        names.append(diabetes.feature_names[i])\n",
    "names = \", \".join(names)\n",
    "print(\"There are \" + str(num_feats) + \" features used by optimal lasso for diabetes.data\")\n",
    "print(\"And their names are: \" + names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "0c56fa3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The training coefficient of determination for scaled diabetes.data is with optimal regularisation parameter:\n",
      "0.5301966316855677\n",
      "\n",
      "The test coefficient of determination for scaled diabetes.data is with optimal regularisation parameter:\n",
      "0.4493607313568915\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"The training coefficient of determination for scaled diabetes.data is with optimal regularisation parameter:\")\n",
    "print(str(optimal_cd_train) + \"\\n\")\n",
    "print(\"The test coefficient of determination for scaled diabetes.data is with optimal regularisation parameter:\")\n",
    "print(str(optimal_cd_test) + \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93b1173c",
   "metadata": {},
   "source": [
    "# Question 11"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70a7c680",
   "metadata": {},
   "source": [
    "## splitting new_X_train into proper and calibration sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "1dfd6fe1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# new_X_train, new_X_test, new_y_train, new_y_test\n",
    "\n",
    "X_train_pr, X_calib, y_train_pr, y_calib = train_test_split(new_X_train, new_y_train, random_state = 13, test_size = 99)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20028c9c",
   "metadata": {},
   "source": [
    "## pre-processing proper and calib training sets, and new_X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "0c3a6600",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(X_train_pr)\n",
    "\n",
    "X_pr_scaled = scaler.transform(X_train_pr)\n",
    "X_calib_scaled = scaler.transform(X_calib)\n",
    "X_test_scaled = scaler.transform(new_X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "830190ca",
   "metadata": {},
   "source": [
    "## First, we need to find parameters for lasso using cross-validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "677c7a24",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The chosen parameter after fitting grid_search with proper training set is:\n",
      "1.7000000000000002\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# chosen parameter will be stored in the variable below.\n",
    "best_C = 0\n",
    "\n",
    "# we had defined grid_search previously on (10), we fit it with our new proper sets.\n",
    "grid_search.fit(X_pr_scaled, y_train_pr)\n",
    "\n",
    "best_C = grid_search.best_params_['alpha']\n",
    "\n",
    "print(\"The chosen parameter after fitting grid_search with proper training set is:\")\n",
    "print(best_C)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "837ac6fe",
   "metadata": {},
   "source": [
    "## for us to calculate non-conformity measure, we need to have a method that finds predicted label for each test sample."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "5d408e91",
   "metadata": {},
   "outputs": [],
   "source": [
    "# make lasso object with chosen parameter\n",
    "lasso = Lasso(alpha = best_C)\n",
    "# fit lasso with training set proper\n",
    "lasso.fit(X_pr_scaled, y_train_pr)\n",
    "\n",
    "# store predicted labels for our scaled test set.\n",
    "test_predictions = lasso.predict(X_test_scaled)\n",
    "\n",
    "# store predicted labels for our scaled calibration set\n",
    "calib_predictions = lasso.predict(X_calib_scaled)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d998fbf",
   "metadata": {},
   "source": [
    "## find non-conformity scores for test and calibration samples\n",
    "### we start by defining a method that calculates and returns a list of non=conformity scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "9c0b5d85",
   "metadata": {},
   "outputs": [],
   "source": [
    "def non_conform_scores(predictions, actual):\n",
    "    scores = []\n",
    "    for i in range(len(predictions)):\n",
    "        score =  abs(actual[i] - predictions[i])\n",
    "        scores.append(score)\n",
    "    return scores"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00ac7537",
   "metadata": {},
   "source": [
    "### store calibration and test non_conformity scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "72a9770d",
   "metadata": {},
   "outputs": [],
   "source": [
    "NC_calib = non_conform_scores(calib_predictions, y_calib)\n",
    "NC_test = non_conform_scores(test_predictions, new_y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1a841a0",
   "metadata": {},
   "source": [
    "### methods for finding the rank of non-conformal scores, finding the prediction set, finding p-values, and the error rate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "60383a37",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bisect import bisect\n",
    "\n",
    "def find_rank(scores, sample):\n",
    "    # sorting list of non-conformity scores in ascending order to find ranks later.\n",
    "    scores.sort()\n",
    "    rank = bisect(scores, sample)\n",
    "    # the samplesare sorted in ascending order, but we want to return the rank of sample in descending.\n",
    "    return len(scores) - rank + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "1ff295cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def p_value(rank, num_scores):\n",
    "    return (rank / (num_scores + 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "9182c066",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prediction_set(p_values, sig_level):\n",
    "    pred_set = []\n",
    "    for i in p_values:\n",
    "        if i > sig_level:\n",
    "            pred_set.append(i)\n",
    "    return pred_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "31ba9085",
   "metadata": {},
   "outputs": [],
   "source": [
    "def error_rate(test_size, pred_set_size):\n",
    "    return 1 - (pred_set_size / test_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae5ed619",
   "metadata": {},
   "source": [
    "## error rate at significance level = 0.05"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "f16f1000",
   "metadata": {},
   "outputs": [],
   "source": [
    "significance_level = 0.05\n",
    "# a list to store p_values for each test sample\n",
    "p_values = []\n",
    "# the number of calibration non-conformity scores\n",
    "num_scores = len(NC_calib)\n",
    "\n",
    "# store all the p_values for the test set\n",
    "for i in range(len(NC_test)):\n",
    "    rank = find_rank(NC_calib, NC_test[i])\n",
    "    p_values.append(p_value(rank, num_scores))\n",
    "    \n",
    "# once all p-values are found we can find the prediction set.\n",
    "pred_set = prediction_set(p_values, significance_level)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "fa7b3fea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The error rate at significance level 5% is:\n",
      "0.08108108108108103\n"
     ]
    }
   ],
   "source": [
    "err_rate = error_rate(len(X_test_scaled), len(pred_set))\n",
    "\n",
    "print(\"The error rate at significance level 5% is:\")\n",
    "print(err_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3a19565",
   "metadata": {},
   "source": [
    "## prediction intervals at significance level = 0.05"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "f454ff05",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The prediction intervals for test samples are:\n",
      "Sample x*1 -> [165, 296] \n",
      " \n",
      "Sample x*2 -> [-10, 121] \n",
      " \n",
      "Sample x*3 -> [87, 217] \n",
      " \n",
      "Sample x*4 -> [126, 256] \n",
      " \n",
      "Sample x*5 -> [204, 335] \n",
      " \n",
      "Sample x*6 -> [72, 203] \n",
      " \n",
      "Sample x*7 -> [110, 240] \n",
      " \n",
      "Sample x*8 -> [135, 266] \n",
      " \n",
      "Sample x*9 -> [177, 307] \n",
      " \n",
      "Sample x*10 -> [17, 147] \n",
      " \n",
      "Sample x*11 -> [107, 238] \n",
      " \n",
      "Sample x*12 -> [167, 297] \n",
      " \n",
      "Sample x*13 -> [24, 155] \n",
      " \n",
      "Sample x*14 -> [114, 245] \n",
      " \n",
      "Sample x*15 -> [99, 230] \n",
      " \n",
      "Sample x*16 -> [55, 186] \n",
      " \n",
      "Sample x*17 -> [40, 171] \n",
      " \n",
      "Sample x*18 -> [162, 292] \n",
      " \n",
      "Sample x*19 -> [27, 157] \n",
      " \n",
      "Sample x*20 -> [112, 242] \n",
      " \n",
      "Sample x*21 -> [24, 154] \n",
      " \n",
      "Sample x*22 -> [58, 189] \n",
      " \n",
      "Sample x*23 -> [16, 146] \n",
      " \n",
      "Sample x*24 -> [31, 162] \n",
      " \n",
      "Sample x*25 -> [77, 208] \n",
      " \n",
      "Sample x*26 -> [123, 254] \n",
      " \n",
      "Sample x*27 -> [19, 149] \n",
      " \n",
      "Sample x*28 -> [83, 213] \n",
      " \n",
      "Sample x*29 -> [101, 231] \n",
      " \n",
      "Sample x*30 -> [-12, 119] \n",
      " \n",
      "Sample x*31 -> [145, 276] \n",
      " \n",
      "Sample x*32 -> [58, 188] \n",
      " \n",
      "Sample x*33 -> [88, 219] \n",
      " \n",
      "Sample x*34 -> [95, 226] \n",
      " \n",
      "Sample x*35 -> [190, 321] \n",
      " \n",
      "Sample x*36 -> [129, 259] \n",
      " \n",
      "Sample x*37 -> [64, 194] \n",
      " \n",
      "Sample x*38 -> [89, 220] \n",
      " \n",
      "Sample x*39 -> [107, 237] \n",
      " \n",
      "Sample x*40 -> [46, 176] \n",
      " \n",
      "Sample x*41 -> [51, 181] \n",
      " \n",
      "Sample x*42 -> [102, 233] \n",
      " \n",
      "Sample x*43 -> [54, 185] \n",
      " \n",
      "Sample x*44 -> [76, 207] \n",
      " \n",
      "Sample x*45 -> [127, 258] \n",
      " \n",
      "Sample x*46 -> [86, 217] \n",
      " \n",
      "Sample x*47 -> [30, 161] \n",
      " \n",
      "Sample x*48 -> [-13, 117] \n",
      " \n",
      "Sample x*49 -> [-13, 118] \n",
      " \n",
      "Sample x*50 -> [71, 202] \n",
      " \n",
      "Sample x*51 -> [26, 156] \n",
      " \n",
      "Sample x*52 -> [122, 252] \n",
      " \n",
      "Sample x*53 -> [-15, 115] \n",
      " \n",
      "Sample x*54 -> [89, 220] \n",
      " \n",
      "Sample x*55 -> [60, 191] \n",
      " \n",
      "Sample x*56 -> [23, 154] \n",
      " \n",
      "Sample x*57 -> [122, 252] \n",
      " \n",
      "Sample x*58 -> [38, 168] \n",
      " \n",
      "Sample x*59 -> [135, 265] \n",
      " \n",
      "Sample x*60 -> [207, 338] \n",
      " \n",
      "Sample x*61 -> [213, 344] \n",
      " \n",
      "Sample x*62 -> [106, 237] \n",
      " \n",
      "Sample x*63 -> [6, 137] \n",
      " \n",
      "Sample x*64 -> [19, 150] \n",
      " \n",
      "Sample x*65 -> [34, 164] \n",
      " \n",
      "Sample x*66 -> [43, 174] \n",
      " \n",
      "Sample x*67 -> [63, 193] \n",
      " \n",
      "Sample x*68 -> [96, 226] \n",
      " \n",
      "Sample x*69 -> [94, 225] \n",
      " \n",
      "Sample x*70 -> [-19, 112] \n",
      " \n",
      "Sample x*71 -> [86, 217] \n",
      " \n",
      "Sample x*72 -> [86, 217] \n",
      " \n",
      "Sample x*73 -> [103, 234] \n",
      " \n",
      "Sample x*74 -> [200, 331] \n",
      " \n",
      "Sample x*75 -> [60, 191] \n",
      " \n",
      "Sample x*76 -> [102, 233] \n",
      " \n",
      "Sample x*77 -> [128, 259] \n",
      " \n",
      "Sample x*78 -> [80, 210] \n",
      " \n",
      "Sample x*79 -> [26, 156] \n",
      " \n",
      "Sample x*80 -> [44, 174] \n",
      " \n",
      "Sample x*81 -> [23, 153] \n",
      " \n",
      "Sample x*82 -> [57, 188] \n",
      " \n",
      "Sample x*83 -> [6, 136] \n",
      " \n",
      "Sample x*84 -> [25, 156] \n",
      " \n",
      "Sample x*85 -> [18, 148] \n",
      " \n",
      "Sample x*86 -> [91, 222] \n",
      " \n",
      "Sample x*87 -> [80, 210] \n",
      " \n",
      "Sample x*88 -> [21, 152] \n",
      " \n",
      "Sample x*89 -> [227, 357] \n",
      " \n",
      "Sample x*90 -> [34, 165] \n",
      " \n",
      "Sample x*91 -> [41, 171] \n",
      " \n",
      "Sample x*92 -> [98, 228] \n",
      " \n",
      "Sample x*93 -> [136, 267] \n",
      " \n",
      "Sample x*94 -> [94, 225] \n",
      " \n",
      "Sample x*95 -> [56, 187] \n",
      " \n",
      "Sample x*96 -> [72, 202] \n",
      " \n",
      "Sample x*97 -> [-7, 124] \n",
      " \n",
      "Sample x*98 -> [66, 197] \n",
      " \n",
      "Sample x*99 -> [188, 319] \n",
      " \n",
      "Sample x*100 -> [72, 203] \n",
      " \n",
      "Sample x*101 -> [141, 272] \n",
      " \n",
      "Sample x*102 -> [176, 306] \n",
      " \n",
      "Sample x*103 -> [57, 188] \n",
      " \n",
      "Sample x*104 -> [113, 244] \n",
      " \n",
      "Sample x*105 -> [65, 195] \n",
      " \n",
      "Sample x*106 -> [148, 279] \n",
      " \n",
      "Sample x*107 -> [84, 214] \n",
      " \n",
      "Sample x*108 -> [15, 146] \n",
      " \n",
      "Sample x*109 -> [1, 131] \n",
      " \n",
      "Sample x*110 -> [82, 213] \n",
      " \n",
      "Sample x*111 -> [55, 185] \n",
      " \n"
     ]
    }
   ],
   "source": [
    "from math import ceil\n",
    "from math import floor\n",
    "\n",
    "k = ceil((1-significance_level) * (num_scores+1))\n",
    "\n",
    "# [k-1] because indices\n",
    "c = NC_calib[k-1]\n",
    "\n",
    "print(\"The prediction intervals for test samples are:\")\n",
    "\n",
    "for i in range(len(NC_test)):\n",
    "    # we take the floor of the lower limit and ceil of the upper limit for a cleaner output\n",
    "    lower = str(floor(test_predictions[i] - c))\n",
    "    upper = str(ceil(test_predictions[i] + c))\n",
    "    sample = \"Sample x*\" +  str(i+1) + \" -> [\" + lower +\", \" + upper +\"] \\n \"\n",
    "    print(sample)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5eeb54e4",
   "metadata": {},
   "source": [
    "## error rate at significance level = 0.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "bbacd3d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "significance_level = 0.2\n",
    "# a list to store p_values for each test sample\n",
    "p_values = []\n",
    "# the number of calibration non-conformity scores\n",
    "num_scores = len(NC_calib)\n",
    "\n",
    "# store all the p_values for the test set\n",
    "for i in range(len(NC_test)):\n",
    "    rank = find_rank(NC_calib, NC_test[i])\n",
    "    p_values.append(p_value(rank, num_scores))\n",
    "    \n",
    "# once all p-values are found we can find the prediction set.\n",
    "pred_set = prediction_set(p_values, significance_level)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "66fed417",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The error rate at significance level 20% is:\n",
      "0.22522522522522526\n"
     ]
    }
   ],
   "source": [
    "err_rate = error_rate(len(X_test_scaled), len(pred_set))\n",
    "\n",
    "print(\"The error rate at significance level 20% is:\")\n",
    "print(err_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f55960d7",
   "metadata": {},
   "source": [
    "## prediction intervals at significance level = 0.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "b12ad8ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The prediction intervals for test samples are:\n",
      "Sample x*1 -> [165, 296] \n",
      " \n",
      "Sample x*2 -> [-10, 121] \n",
      " \n",
      "Sample x*3 -> [87, 217] \n",
      " \n",
      "Sample x*4 -> [126, 256] \n",
      " \n",
      "Sample x*5 -> [204, 335] \n",
      " \n",
      "Sample x*6 -> [72, 203] \n",
      " \n",
      "Sample x*7 -> [110, 240] \n",
      " \n",
      "Sample x*8 -> [135, 266] \n",
      " \n",
      "Sample x*9 -> [177, 307] \n",
      " \n",
      "Sample x*10 -> [17, 147] \n",
      " \n",
      "Sample x*11 -> [107, 238] \n",
      " \n",
      "Sample x*12 -> [167, 297] \n",
      " \n",
      "Sample x*13 -> [24, 155] \n",
      " \n",
      "Sample x*14 -> [114, 245] \n",
      " \n",
      "Sample x*15 -> [99, 230] \n",
      " \n",
      "Sample x*16 -> [55, 186] \n",
      " \n",
      "Sample x*17 -> [40, 171] \n",
      " \n",
      "Sample x*18 -> [162, 292] \n",
      " \n",
      "Sample x*19 -> [27, 157] \n",
      " \n",
      "Sample x*20 -> [112, 242] \n",
      " \n",
      "Sample x*21 -> [24, 154] \n",
      " \n",
      "Sample x*22 -> [58, 189] \n",
      " \n",
      "Sample x*23 -> [16, 146] \n",
      " \n",
      "Sample x*24 -> [31, 162] \n",
      " \n",
      "Sample x*25 -> [77, 208] \n",
      " \n",
      "Sample x*26 -> [123, 254] \n",
      " \n",
      "Sample x*27 -> [19, 149] \n",
      " \n",
      "Sample x*28 -> [83, 213] \n",
      " \n",
      "Sample x*29 -> [101, 231] \n",
      " \n",
      "Sample x*30 -> [-12, 119] \n",
      " \n",
      "Sample x*31 -> [145, 276] \n",
      " \n",
      "Sample x*32 -> [58, 188] \n",
      " \n",
      "Sample x*33 -> [88, 219] \n",
      " \n",
      "Sample x*34 -> [95, 226] \n",
      " \n",
      "Sample x*35 -> [190, 321] \n",
      " \n",
      "Sample x*36 -> [129, 259] \n",
      " \n",
      "Sample x*37 -> [64, 194] \n",
      " \n",
      "Sample x*38 -> [89, 220] \n",
      " \n",
      "Sample x*39 -> [107, 237] \n",
      " \n",
      "Sample x*40 -> [46, 176] \n",
      " \n",
      "Sample x*41 -> [51, 181] \n",
      " \n",
      "Sample x*42 -> [102, 233] \n",
      " \n",
      "Sample x*43 -> [54, 185] \n",
      " \n",
      "Sample x*44 -> [76, 207] \n",
      " \n",
      "Sample x*45 -> [127, 258] \n",
      " \n",
      "Sample x*46 -> [86, 217] \n",
      " \n",
      "Sample x*47 -> [30, 161] \n",
      " \n",
      "Sample x*48 -> [-13, 117] \n",
      " \n",
      "Sample x*49 -> [-13, 118] \n",
      " \n",
      "Sample x*50 -> [71, 202] \n",
      " \n",
      "Sample x*51 -> [26, 156] \n",
      " \n",
      "Sample x*52 -> [122, 252] \n",
      " \n",
      "Sample x*53 -> [-15, 115] \n",
      " \n",
      "Sample x*54 -> [89, 220] \n",
      " \n",
      "Sample x*55 -> [60, 191] \n",
      " \n",
      "Sample x*56 -> [23, 154] \n",
      " \n",
      "Sample x*57 -> [122, 252] \n",
      " \n",
      "Sample x*58 -> [38, 168] \n",
      " \n",
      "Sample x*59 -> [135, 265] \n",
      " \n",
      "Sample x*60 -> [207, 338] \n",
      " \n",
      "Sample x*61 -> [213, 344] \n",
      " \n",
      "Sample x*62 -> [106, 237] \n",
      " \n",
      "Sample x*63 -> [6, 137] \n",
      " \n",
      "Sample x*64 -> [19, 150] \n",
      " \n",
      "Sample x*65 -> [34, 164] \n",
      " \n",
      "Sample x*66 -> [43, 174] \n",
      " \n",
      "Sample x*67 -> [63, 193] \n",
      " \n",
      "Sample x*68 -> [96, 226] \n",
      " \n",
      "Sample x*69 -> [94, 225] \n",
      " \n",
      "Sample x*70 -> [-19, 112] \n",
      " \n",
      "Sample x*71 -> [86, 217] \n",
      " \n",
      "Sample x*72 -> [86, 217] \n",
      " \n",
      "Sample x*73 -> [103, 234] \n",
      " \n",
      "Sample x*74 -> [200, 331] \n",
      " \n",
      "Sample x*75 -> [60, 191] \n",
      " \n",
      "Sample x*76 -> [102, 233] \n",
      " \n",
      "Sample x*77 -> [128, 259] \n",
      " \n",
      "Sample x*78 -> [80, 210] \n",
      " \n",
      "Sample x*79 -> [26, 156] \n",
      " \n",
      "Sample x*80 -> [44, 174] \n",
      " \n",
      "Sample x*81 -> [23, 153] \n",
      " \n",
      "Sample x*82 -> [57, 188] \n",
      " \n",
      "Sample x*83 -> [6, 136] \n",
      " \n",
      "Sample x*84 -> [25, 156] \n",
      " \n",
      "Sample x*85 -> [18, 148] \n",
      " \n",
      "Sample x*86 -> [91, 222] \n",
      " \n",
      "Sample x*87 -> [80, 210] \n",
      " \n",
      "Sample x*88 -> [21, 152] \n",
      " \n",
      "Sample x*89 -> [227, 357] \n",
      " \n",
      "Sample x*90 -> [34, 165] \n",
      " \n",
      "Sample x*91 -> [41, 171] \n",
      " \n",
      "Sample x*92 -> [98, 228] \n",
      " \n",
      "Sample x*93 -> [136, 267] \n",
      " \n",
      "Sample x*94 -> [94, 225] \n",
      " \n",
      "Sample x*95 -> [56, 187] \n",
      " \n",
      "Sample x*96 -> [72, 202] \n",
      " \n",
      "Sample x*97 -> [-7, 124] \n",
      " \n",
      "Sample x*98 -> [66, 197] \n",
      " \n",
      "Sample x*99 -> [188, 319] \n",
      " \n",
      "Sample x*100 -> [72, 203] \n",
      " \n",
      "Sample x*101 -> [141, 272] \n",
      " \n",
      "Sample x*102 -> [176, 306] \n",
      " \n",
      "Sample x*103 -> [57, 188] \n",
      " \n",
      "Sample x*104 -> [113, 244] \n",
      " \n",
      "Sample x*105 -> [65, 195] \n",
      " \n",
      "Sample x*106 -> [148, 279] \n",
      " \n",
      "Sample x*107 -> [84, 214] \n",
      " \n",
      "Sample x*108 -> [15, 146] \n",
      " \n",
      "Sample x*109 -> [1, 131] \n",
      " \n",
      "Sample x*110 -> [82, 213] \n",
      " \n",
      "Sample x*111 -> [55, 185] \n",
      " \n"
     ]
    }
   ],
   "source": [
    "from math import ceil\n",
    "from math import floor\n",
    "\n",
    "k = ceil((1-significance_level) * (num_scores+1))\n",
    "\n",
    "# [k-1] because indices\n",
    "c = NC_calib[k-1]\n",
    "\n",
    "print(\"The prediction intervals for test samples are:\")\n",
    "\n",
    "for i in range(len(NC_test)):\n",
    "    # we take the floor of the lower limit and ceil of the upper limit for a cleaner output\n",
    "    lower = str(floor(test_predictions[i] - c))\n",
    "    upper = str(ceil(test_predictions[i] + c))\n",
    "    sample = \"Sample x*\" +  str(i+1) + \" -> [\" + lower +\", \" + upper +\"] \\n \"\n",
    "    print(sample)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
